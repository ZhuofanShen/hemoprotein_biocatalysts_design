#!/bin/bash
#SBATCH --partition=main           # Partition (job queue)
#SBATCH --job-name monitoring      # Assign a name to the job
#SBATCH --nodes=1                  # Number of nodes
#SBATCH --ntasks=1                 # Number of tasks (usually = cores) on each node
#SBATCH --mem=200                 # Real memory required (MB)
#SBATCH --time=3-00:00:00          # Total run time limit (HH:MM:SS)
#SBATCH --output=slurm.%N.%j.out   # STDOUT output file
#SBATCH --error=slurm.%N.%j.out    # STDERR output file
#SBATCH --export=ALL               # Export you current env to the job env

for pdb in `ls HEM`; do
    cd HEM/${pdb};
    for i in {1..1}; do
        mkdir relax$i;
        cd relax$i;
        slurmit.py --job ${pdb}${i} --command "python ../../../scripts/fast_design.py ../${pdb}_clean.pdb -ref ../${pdb}_clean.pdb -optH -sf ref2015_cst -no_min_sc_ids HEM -n 5 -prefix ${pdb} --score_terms fa_intra_rep_nonprotein:0.545 fa_intra_atr_nonprotein:1";
        cd ..;
    done
    cd ../..;
done
